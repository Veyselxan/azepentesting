import sys, os, json, requests
from socket import *
from urllib.parse import urlparse
from bs4 import BeautifulSoup as BS


class bcolors:
    HEADER = "\033[95m"
    OKBLUE = "\033[94m"
    OKCYAN = "\033[96m"
    OKGREEN = "\033[92m"
    WARNING = "\033[93m"
    FAIL = "\033[91m"
    ENDC = "\033[0m"
    BOLD = "\033[1m"
    UNDERLINE = "\033[4m"

    def disable(self):
        self.HEADER = ""
        self.OKBLUE = ""
        self.OKGREEN = ""
        self.WARNING = ""
        self.BOLD = ""
        self.FAIL = ""
        self.ENDC = ""


external = []
unknown = []
sql_links = list()


def sql_scan(url):

    urls = [
        url + "'",
        url + '"',
        url[:-4] + ";",
        url + ")",
        url + "')",
        url + '")',
        url + "*",
    ]
    vulnerable_text = [
        "MySQL Query fail:",
        "/www/htdocs/",
        "Query failed",
        "mysqli_fetch_array()",
        "mysqli_result",
        "Warning: ",
        "MySQL server",
        "SQL syntax",
        "You have an error in your SQL syntax;",
        "mssql_query()",
        "Incorrect syntax near '='",
        "mssql_num_rows()",
        "Notice: ",
    ]
    try:
        for urlon in urls:
            results = requests.get(urlon)
            data = results.text
            soup = BS(data, features="html.parser")
            for vuln in vulnerable_text:
                if vuln in data:
                    string = vuln
                    vulnerable = True
        if vulnerable:
            return True
    except:
        return False


def is_url(url):
    try:
        result = urlparse(url)
        return all([result.scheme, result.netloc])
    except ValueError:
        return False


def extractor(soup, host):
    all_links = list()

    for link in soup.find_all("a", href=True):
        if link["href"].startswith(""):
            if host + link["href"] not in all_links:

                if is_url(link["href"]) == False or link["href"].find(host) != -1:
                    if is_url(link["href"]):
                        all_links.append(link["href"])
                    else:
                        if len(link["href"]) > 1:
                            if link["href"][0] == "/":
                                link["href"] = link["href"][1:]
                                all_links.append(host + link["href"])
                            else:
                                all_links.append(host + link["href"])
    return all_links


def xploit(link, host=None, cookie=""):
    if host is None:
        host = link
    cookies = ""
    headers = {
        "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.111 Safari/537.36"
    }

    if len(cookie) > 5:
        cookie = cookie.split(":")
        cookies = {cookie[0]: cookie[1]}
    res = requests.get(link, allow_redirects=True, headers=headers, cookies=cookies)
    print(res)
    soup = BS(res.text, "lxml")
    return extractor(soup, host)

def port_scan(ipsaytaİP,port,desc=''):
      s = socket(AF_INET, SOCK_STREAM)
      cavab = s.connect_ex((ipsaytaİP, port))
      if cavab == 0:
        print(bcolors.OKGREEN + "Port %d: OPEN  %a \n" % (port,desc)  + bcolors.ENDC)
      else:
        print("Port %d: CLOSE  %a \n" % (port,desc))
      s.close()
def level2(linklist, host):
    final_list = list()
    for link in linklist:

        for x in xploit(link, host):

            if x not in final_list:
                final_list.append(x)
                if sql_scan(x):
                    sql_links.append(x)
                    print(
                        bcolors.FAIL
                        + "Vulnerable <-----------------> "
                        + x
                        + bcolors.ENDC
                    )
                else:
                    print("No vulnerable <-----------------> " + x)
        if link not in final_list:
            final_list.append(link)
    return final_list


## Sql
if sys.version[0] == 2:
    sys.exit()
else:

    def diryoxla(sayt, import_listyeryol):

        cavab_kodu = requests.get(sayt + import_listyeryol).status_code
        if cavab_kodu == 200:
            print("\nhttp://%s/%s  : Found  " % (sayt, import_listyeryol))

    def scan_comp():
        print(
            bcolors.OKGREEN
            + "***********************************************"
            + bcolors.ENDC
        )
        print(bcolors.OKBLUE + "Search Complete" + bcolors.ENDC)
        print(
            bcolors.OKGREEN
            + "***********************************************"
            + bcolors.ENDC
        )
        print("Get a choice \n")
        print("1. Ip port search")
        print("2. Dirb Search")
        print("3. Wordpress user enumeration ")
        print("4. SQL injection \n")
        scan()

    def scan():

        secim = input("Selection :")
        if secim == "1":
            ipsayta = input("Enter the ip: ")
            print("Select Port Search \n")
            print("1 Main ports")
            print("2 With line (1-5000) \n")
            portsecim = input("Selection: ")
            ipsaytaİP = gethostbyname(ipsayta)
            (print("Search start ... \n"), ipsaytaİP)
            p = open('services.json',)
            ports = json.load(p)

            for i in ports:
                port = ports[i]['ports'][0]
                port = port.split("/")
                desc = ''
                try:
                    desc = ports[i]['description']
                except KeyError:
                    print("s age is unknown.")

                        
                #desc = ports[i]['description'] if ports[i]['description'] else ''
                port_scan(ipsaytaİP,int(port[0]), desc )    


            # for i in ports['ports']:
            #     if issubclass(type(ports['ports'][i]), list):
            #         #print(ports['ports'][i][0]['description'])
            #         port = str(ports['ports'][i][0]['port'])
            #         port  =port.split("-")
            #         port_scan(ipsaytaİP,int(port[0]), ports['ports'][i][0]['description'])
            #     else:
            #         port  =ports['ports'][i]['port'].split("-")
            #         port_scan(ipsaytaİP,int(port[0]), ports['ports'][i]['description'])

              
        elif secim == "2":

            sayt = input("Enter the domain (https://sayt.com/): ")
            listyer = input("List (list.txt) : ")

            # hostsocket = socket(AF_INET, SOCK_STREAM)

            # status = hostsocket.connect_ex((sayt, 80))
            # hostsocket.close()
            # if status == 0:
            #      print('\n==connect created==')
            # else:
            #      print('\n===connect no created %s===') % sayt
            # sys.exit(1)

            print("\n This list is included, it may take up to a second.")
            try:
                with open(listyer) as (file):
                    import_listyer = file.read().strip().split("\n")
            except IOError:
                print("\n Not included")
                sys.exit(1)
            print(len(import_listyer))
            for i in import_listyer:
                # print(i)
                diryoxla(sayt, i)
        elif secim == "3":

            url = input("Enter the domain (https://sayt.com/): ")
            urll = url + "wp-json/wp/v2/users"
            headers = {
                "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.111 Safari/537.36"
            }

            r = requests.get(urll, headers=headers)
            try:
                data = r.json()
                for adi in data:
                    print(adi["slug"])
            except:
                print("No user!")
            scan_comp()
        elif secim == "4":
            url = input("Enter the domain (https://sayt.com/): ")
            cookie = input("Login cookies (name:token): ")
            links = level2(xploit(url, cookie=cookie), url)
            if len(links) > 1:
                print("\n\n SQL injection : \n\n")
                for link in sql_links:
                    print(">\t", link)
            else:
                print("\n\nNo Link Found\n\n")
            scan_comp()
        else:
            scan_comp()
            sys.exit()

    os.system("apt-get install figlet")
    os.system("clear")
    os.system("figlet Aze Pentesting Tools ")
    print(
        bcolors.OKGREEN
        + "***********************************************"
        + bcolors.ENDC
    )
    print(bcolors.BOLD + "Aze Pentesting Tools V 1.2" + bcolors.ENDC)
    print(bcolors.BOLD + "Author: Veysel xan" + bcolors.ENDC)
    print(bcolors.BOLD + "Sayt: https://veysel-xan.com" + bcolors.ENDC)
    print(bcolors.BOLD + "Facebook: https://www.facebook.com/Veyselxan" + bcolors.ENDC)
    print(
        bcolors.OKGREEN
        + "***********************************************"
        + bcolors.ENDC
    )
    print("Get a choice \n")
    print("1. Ip port search")
    print("2. Dirb Search")
    print("3. Wordpress user enumeration ")
    print("4. SQL injection \n")

    scan()
